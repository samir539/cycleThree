{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\xamir\\anaconda3\\lib\\site-packages (0.90)\n",
      "Requirement already satisfied: numpy in c:\\users\\xamir\\anaconda3\\lib\\site-packages (from xgboost) (1.16.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\xamir\\anaconda3\\lib\\site-packages (from xgboost) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\test.csv\")\n",
    "QM9Data = pd.read_pickle(r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\QM9\\data.covs.pickle\")\n",
    "structures_df_full = pd.read_csv(r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\structures.csv\", dtype={'atom_index': np.int8})\n",
    "sub = pd.read_csv(r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9Data = QM9Data.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9Data = QM9Data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QM9Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QM9Data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QM9Data is split into train and test dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9Train = QM9Data.iloc[:4658147, :]\n",
    "QM9Test = QM9Data.iloc[4658147:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = round(0.02*train.shape[0])\n",
    "# QM9Train = QM9Train[:size]\n",
    "# QM9Test = QM9Test[:size]\n",
    "# structures_df_full = structures_df_full[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QM9Train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [00:00<00:00, 3627092.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting and condensing bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [00:11<00:00, 209622.01it/s]\n",
      "100%|██████████| 2358657/2358657 [00:14<00:00, 161052.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating hybridization....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [01:25<00:00, 27506.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# libraries required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def reduce_memory(df, verbose=True):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe required to decrease the memory usage\n",
    "    :param: verbose - show logging output if 'Ture'\n",
    "\n",
    "    Goal: Reduce the memory usage by decreasing the type of the value if applicable\n",
    "\n",
    "    Return: original dataframe with lower memory usage\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int64', 'int16', 'int32', 'float64', 'float32', 'float16']\n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_memory, 100 * (start_memory - end_memory) / start_memory))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def struc1_merge(df1, df2, index):\n",
    "    \"\"\"\n",
    "    :param: df1 - training data\n",
    "    :param: df2 - structure data after being added electronegativity, radius, bond_lengths, hybridization, surrounding atoms (bonds),\n",
    "            position info. (x, y, z)\n",
    "    :param: index - atom_index in the coupling\n",
    "\n",
    "    Goal: Merge original training dataframe with processed structure data to form a new dataframe for further training process\n",
    "\n",
    "    Return: Merged dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    struc1_train_merge = pd.merge(df1, df2, how='left',\n",
    "                                  left_on=['molecule_name', f'atom_index_{index}', f'atom_{index}', f'x_{index}', f'y_{index}', f'z_{index}'],\n",
    "                                  right_on=['molecule_name', 'atom_index', 'atom', 'x', 'y', 'z'])\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.drop(['n_bonds'], axis=1)\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.rename(columns={'EN': f'EN_{index}',\n",
    "                                                            'RD': f'RD_{index}',\n",
    "                                                            'bond_lengths': f'bond_lengths_{index}',\n",
    "                                                            'hybri': f'hybri_{index}',\n",
    "                                                            'bonds': f'bonds_{index}',\n",
    "                                                            'pi_bonds': f'pi_bonds_{index}'})\n",
    "    \n",
    "    return struc1_train_merge\n",
    "\n",
    "\n",
    "def n_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structure.csv from local data\n",
    "    \n",
    "    Goal: Calculate the number of bonds for each molecule.\n",
    "\n",
    "    Return: Structure dataframe with number of bonds (n_bonds) and lists consisting of indexes of connecting atoms (bonds)\n",
    "    \"\"\"\n",
    "\n",
    "    i_atom = structures['atom_index'].values\n",
    "    p = structures[['x', 'y', 'z']].values\n",
    "    p_compare = p\n",
    "    m = structures['molecule_name'].values\n",
    "    m_compare = m\n",
    "    r = structures['RD'].values\n",
    "    r_compare = r\n",
    "\n",
    "    source_row = np.arange(len(structures))\n",
    "    max_atoms = 28\n",
    "\n",
    "    bonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\n",
    "    bond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n",
    "\n",
    "    print('Calculating bonds')\n",
    "\n",
    "    for i in tqdm(range(max_atoms-1)):\n",
    "        p_compare = np.roll(p_compare, -1, axis=0)\n",
    "        m_compare = np.roll(m_compare, -1, axis=0)\n",
    "        r_compare = np.roll(r_compare, -1, axis=0)\n",
    "\n",
    "        mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n",
    "        dists = np.linalg.norm(p - p_compare, axis=1) * mask\n",
    "        r_bond = r + r_compare\n",
    "\n",
    "        bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n",
    "\n",
    "        source_row = source_row\n",
    "        target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n",
    "\n",
    "        source_atom = i_atom\n",
    "        target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n",
    "\n",
    "        bonds[(source_row, target_atom)] = bond\n",
    "        bonds[(target_row, source_atom)] = bond\n",
    "        bond_dists[(source_row, target_atom)] = dists\n",
    "        bond_dists[(target_row, source_atom)] = dists\n",
    "\n",
    "    bonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\n",
    "    bonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\n",
    "    bond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\n",
    "    bond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n",
    "\n",
    "    print('Counting and condensing bonds')\n",
    "\n",
    "    bonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\n",
    "    bond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\n",
    "    n_bonds = [len(x) for x in bonds_numeric]\n",
    "\n",
    "    #bond_data = {'bond_' + str(i):col for i, col in enumerate(np.transpose(bonds))}\n",
    "    #bond_data.update({'bonds_numeric':bonds_numeric, 'n_bonds':n_bonds})\n",
    "\n",
    "    bond_data = {'bonds':bonds_numeric, 'n_bonds':n_bonds, 'bond_lengths':bond_lengths}\n",
    "    bond_df = pd.DataFrame(bond_data)\n",
    "    structures = structures.join(bond_df)\n",
    "    \n",
    "    return structures\n",
    "\n",
    "\n",
    "def struc_merge(df, struc, index):\n",
    "    \"\"\"\n",
    "    :param: df - The dataframe to be merged with structure data\n",
    "    :param: struc - structure data\n",
    "    :param: index - index of atom in the coupling\n",
    "\n",
    "    Goal: Merger two dataframe.\n",
    "\n",
    "    Return: a new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge train and structures data based on the atom index\n",
    "    df_struc = pd.merge(df, struc, how='left', \n",
    "                        left_on=['molecule_name', f'atom_index_{index}'], \n",
    "                        right_on=['molecule_name', 'atom_index'])\n",
    "\n",
    "    # Drop the atom index column\n",
    "    df_struc = df_struc.drop('atom_index', axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    df_struc = df_struc.rename(columns={'atom': f'atom_{index}',\n",
    "                                        'x': f'x_{index}',\n",
    "                                        'y': f'y_{index}',\n",
    "                                        'z': f'z_{index}'})\n",
    "\n",
    "    return df_struc\n",
    "\n",
    "\n",
    "def distance(df, structures):\n",
    "    \"\"\"\n",
    "    :param: df - Data that need to calculate distance\n",
    "\n",
    "    Goal: Calculate the distance between two spins\n",
    "\n",
    "    Return: DataFrame with distance added\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy of  the data for avoiding changing the original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Merge data\n",
    "    df_copy = struc_merge(df_copy, structures, 0)\n",
    "    df_copy = struc_merge(df_copy, structures, 1)\n",
    "\n",
    "    # This block for calculating the distance between two spins\n",
    "    df_p_0 = df_copy[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df_copy[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "    df_copy['distance'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def hybridization(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate each hybridization in the structures data\n",
    "\n",
    "    Return: structure data with hybridization column added\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Calculating hybridization....')\n",
    "    \n",
    "    # 'C' has different types of hybridizations with different number of bonds.\n",
    "    # '4' for four bonds\n",
    "    hybri_dict = {'C': {'4': 3, '3': 2, '2': 2, '1': 0},\n",
    "                  'N': {'4': 0, '3': 3, '2': 2, '1': 1},\n",
    "                  'O': {'2': 2, '1': 1},\n",
    "                  'H': {'1': 0},\n",
    "                  'F': {'1': 0}}\n",
    "                # 3 bonds- sp3, 2 - sp2, 1 - sp\n",
    "    \n",
    "    hybri = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        hybri.append(hybri_dict[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "    \n",
    "    structures['hybri'] = hybri\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def pi_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate the number of pi_bonds for each atom\n",
    "\n",
    "    Return: structures with pi_bonds column added\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Calculating pi bonds....')\n",
    "    \n",
    "    # The number of atoms connecting to an atom is related with the number of pi bonds.\n",
    "    # Eg: In 'C', if there are 4 bonds around, then the number of pi bonds is 0.\n",
    "    pi_bond = {'C': {'4': 0, '2': 2, '3': 1},\n",
    "               'N': {'4': 0, '3': 0, '2': 1, '1': 2},\n",
    "               'O': {'1': 1, '2': 0},\n",
    "               'H': {'1': 0},\n",
    "               'F': {'1': 0}}\n",
    "\n",
    "    pi_bond_ = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        pi_bond_.append(pi_bond[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "\n",
    "    structures['pi_bonds'] = pi_bond_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def electronegativity(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an electrinegativity for each atom\n",
    "\n",
    "    Return: structures with electrineativity column added\n",
    "    \"\"\"\n",
    "    \n",
    "    electronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n",
    "    en_ = [electronegativity[x] for x in tqdm(atom_name)]\n",
    "\n",
    "    structures['EN'] = en_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def radius(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an radius for each atom\n",
    "\n",
    "    Return: structures with radius column added\n",
    "    \"\"\"\n",
    "    \n",
    "    atomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n",
    "\n",
    "    fudge_factor = 0.05\n",
    "    atomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\n",
    "    rd_ = [atomic_radius[x] for x in atom_name]\n",
    "\n",
    "    structures['RD'] = rd_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    \"\"\"\n",
    "    :param: df_1 - train data\n",
    "    :param: df_2 - structure data\n",
    "    :param: atom_ind - atom index in coupling\n",
    "\n",
    "    Goal: Merge two dataframe for further using\n",
    "\n",
    "    Return: A new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_closest(df_train):\n",
    "    df_temp=df_train.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"distance\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"distance\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df_train = map_atom_info(df_train,df_temp, atom_idx)\n",
    "        df_train = df_train.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                            'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                            'x_closest': f'x_closest_{atom_idx}',\n",
    "                                            'y_closest': f'y_closest_{atom_idx}',\n",
    "                                            'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def add_cos_features(df):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe containing necessary data for calculating the cosine value\n",
    "\n",
    "    Goal: Calculating cosine value\n",
    "\n",
    "    Return: dataframe with cosine data added\n",
    "    \"\"\"\n",
    "\n",
    "    # The modulus of the \n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    \n",
    "    # Unit vector along each direction\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    \n",
    "    # Ratio between the difference along each direction to the distance\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"distance\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"distance\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"distance\"]\n",
    "\n",
    "    # Cosine of each component\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "\n",
    "    # Angle for each component\n",
    "    df[\"Angle\"] = df[\"cos_0_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_0\"] = df[\"cos_0\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_1\"] = df[\"cos_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# # File paths\n",
    "# train_path = r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\train.csv\"\n",
    "# structures_path = r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\structures.csv\"\n",
    "# test_path = r\"C:\\Users\\xamir\\Documents\\UROP19\\DataSets\\test.csv\"\n",
    "\n",
    "# read data from local address\n",
    "# train_df_full = pd.read_csv(train_path, index_col=0)\n",
    "# structures_df_full = pd.read_csv(structures_path, dtype={'atom_index': np.int8})\n",
    "# test_df_full = pd.read_csv(test_path)\n",
    "\n",
    "# Add distance feature to the test and trin data\n",
    "train_df = distance(QM9Train, structures_df_full)\n",
    "test_df = distance(QM9Test, structures_df_full)\n",
    "\n",
    "# ndarray with names of each atom in the structures csv\n",
    "atom = structures_df_full['atom'].values\n",
    "\n",
    "# Add electronegativity and radius colmun to the structures csv\n",
    "structures = electronegativity(atom, structures_df_full)\n",
    "structures = radius(atom, structures)\n",
    "\n",
    "# Add number of bonds and connecting atoms columns\n",
    "structures = n_bonds(structures)\n",
    "\n",
    "# Add hybridization column\n",
    "structures = hybridization(structures)\n",
    "\n",
    "# # Add pi_bonds column\n",
    "# structures = pi_bonds(structures)\n",
    "\n",
    "# Merge structures data and train data\n",
    "struc_train = struc1_merge(train_df, structures, 0)\n",
    "struc_train = struc1_merge(struc_train, structures, 1)\n",
    "\n",
    "struc_train = struc_train.drop(['atom_index_x', 'atom_x', 'x_x', 'y_x', 'z_x',\n",
    "                                'atom_index_y', 'atom_y','x_y', 'y_y', 'z_y'], axis=1)\n",
    "\n",
    "# Add bond angle column\n",
    "struc_train = create_closest(struc_train)\n",
    "struc_train = add_cos_features(struc_train)\n",
    "\n",
    "# The list of type for further training\n",
    "type_list = list(struc_train['type'].unique())\n",
    "\n",
    "# Drop the target column for training\n",
    "y = struc_train['scalar_coupling_constant']\n",
    "struc_train = struc_train.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "# Select features for training\n",
    "X = struc_train[['molecule_name', 'type', 'rc_A', 'rc_B',\n",
    "       'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U',\n",
    "       'H', 'G', 'Cv', 'freqs_min', 'freqs_max', 'freqs_mean', 'linear',\n",
    "       'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
    "       'mulliken_atom_1', 'x_0', 'y_0', 'z_0', 'EN_x', 'RD_x',\n",
    "       'x_1', 'y_1', 'z_1', 'EN_y', 'RD_y', 'distance', 'EN_0',\n",
    "       'RD_0','hybri_0', 'EN_1', 'RD_1', 'hybri_1', 'atom_index_closest_0',\n",
    "       'distance_closest_0', 'x_closest_0', 'y_closest_0', 'z_closest_0',\n",
    "       'atom_index_closest_1', 'distance_closest_1', 'x_closest_1',\n",
    "       'y_closest_1', 'z_closest_1', 'distance_0', 'distance_1', 'cos_0_1',\n",
    "       'cos_0', 'cos_1', 'Angle']]\n",
    "\n",
    "#test\n",
    "\n",
    "struc_test = struc1_merge(test_df, structures, 0)\n",
    "struc_test = struc1_merge(struc_test, structures, 1)\n",
    "\n",
    "struc_test = struc_test.drop(['atom_index_x', 'atom_x', 'x_x', 'y_x', 'z_x',\n",
    "                                'atom_index_y', 'atom_y','x_y', 'y_y', 'z_y'], axis=1)\n",
    "\n",
    "\n",
    "struc_test = create_closest(struc_test)\n",
    "struc_test = add_cos_features(struc_test)\n",
    "\n",
    "# The list of type for further training\n",
    "type_list = list(struc_test['type'].unique())\n",
    "\n",
    "\n",
    "# Select features for training\n",
    "X_test = struc_test[['molecule_name', 'type', 'rc_A', 'rc_B',\n",
    "       'rc_C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U',\n",
    "       'H', 'G', 'Cv', 'freqs_min', 'freqs_max', 'freqs_mean', 'linear',\n",
    "       'mulliken_min', 'mulliken_max', 'mulliken_atom_0',\n",
    "       'mulliken_atom_1', 'x_0', 'y_0', 'z_0', 'EN_x', 'RD_x',\n",
    "       'x_1', 'y_1', 'z_1', 'EN_y', 'RD_y', 'distance', 'EN_0',\n",
    "       'RD_0','hybri_0', 'EN_1', 'RD_1', 'hybri_1', 'atom_index_closest_0',\n",
    "       'distance_closest_0', 'x_closest_0', 'y_closest_0', 'z_closest_0',\n",
    "       'atom_index_closest_1', 'distance_closest_1', 'x_closest_1',\n",
    "       'y_closest_1', 'z_closest_1', 'distance_0', 'distance_1', 'cos_0_1',\n",
    "       'cos_0', 'cos_1', 'Angle']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>type</th>\n",
       "      <th>rc_A</th>\n",
       "      <th>rc_B</th>\n",
       "      <th>rc_C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>U0</th>\n",
       "      <th>U</th>\n",
       "      <th>H</th>\n",
       "      <th>G</th>\n",
       "      <th>Cv</th>\n",
       "      <th>freqs_min</th>\n",
       "      <th>freqs_max</th>\n",
       "      <th>freqs_mean</th>\n",
       "      <th>linear</th>\n",
       "      <th>mulliken_min</th>\n",
       "      <th>mulliken_max</th>\n",
       "      <th>mulliken_atom_0</th>\n",
       "      <th>mulliken_atom_1</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>EN_x</th>\n",
       "      <th>RD_x</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>EN_y</th>\n",
       "      <th>RD_y</th>\n",
       "      <th>distance</th>\n",
       "      <th>EN_0</th>\n",
       "      <th>RD_0</th>\n",
       "      <th>hybri_0</th>\n",
       "      <th>EN_1</th>\n",
       "      <th>RD_1</th>\n",
       "      <th>hybri_1</th>\n",
       "      <th>atom_index_closest_0</th>\n",
       "      <th>distance_closest_0</th>\n",
       "      <th>x_closest_0</th>\n",
       "      <th>y_closest_0</th>\n",
       "      <th>z_closest_0</th>\n",
       "      <th>atom_index_closest_1</th>\n",
       "      <th>distance_closest_1</th>\n",
       "      <th>x_closest_1</th>\n",
       "      <th>y_closest_1</th>\n",
       "      <th>z_closest_1</th>\n",
       "      <th>distance_0</th>\n",
       "      <th>distance_1</th>\n",
       "      <th>cos_0_1</th>\n",
       "      <th>cos_0</th>\n",
       "      <th>cos_1</th>\n",
       "      <th>Angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>157.711800000000011</td>\n",
       "      <td>157.709969999999998</td>\n",
       "      <td>157.70698999999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.210000000000001</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.364100000000001</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478929999999998</td>\n",
       "      <td>-40.476061999999999</td>\n",
       "      <td>-40.475116999999997</td>\n",
       "      <td>-40.498596999999997</td>\n",
       "      <td>6.468999999999999</td>\n",
       "      <td>1341.307000000000016</td>\n",
       "      <td>3151.707800000000134</td>\n",
       "      <td>2182.525477777777724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.002150416</td>\n",
       "      <td>-0.0060313176</td>\n",
       "      <td>0.0019761204</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>3</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>-0.5408150690</td>\n",
       "      <td>1.447526614</td>\n",
       "      <td>-0.8766437152</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>0.333334935854766</td>\n",
       "      <td>179.999998792581749</td>\n",
       "      <td>109.471318021912978</td>\n",
       "      <td>70.528681978087036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>157.711800000000011</td>\n",
       "      <td>157.709969999999998</td>\n",
       "      <td>157.70698999999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.210000000000001</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.364100000000001</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478929999999998</td>\n",
       "      <td>-40.476061999999999</td>\n",
       "      <td>-40.475116999999997</td>\n",
       "      <td>-40.498596999999997</td>\n",
       "      <td>6.468999999999999</td>\n",
       "      <td>1341.307000000000016</td>\n",
       "      <td>3151.707800000000134</td>\n",
       "      <td>2182.525477777777724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.133922</td>\n",
       "      <td>0.002150416</td>\n",
       "      <td>-0.0060313176</td>\n",
       "      <td>0.0019761204</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0117308430</td>\n",
       "      <td>1.463751162</td>\n",
       "      <td>0.0002765748</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.783119756038801</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>-0.333287053439111</td>\n",
       "      <td>144.734230817948855</td>\n",
       "      <td>35.265822650766161</td>\n",
       "      <td>109.468408167182687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>157.711800000000011</td>\n",
       "      <td>157.709969999999998</td>\n",
       "      <td>157.70698999999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.210000000000001</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.364100000000001</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478929999999998</td>\n",
       "      <td>-40.476061999999999</td>\n",
       "      <td>-40.475116999999997</td>\n",
       "      <td>-40.498596999999997</td>\n",
       "      <td>6.468999999999999</td>\n",
       "      <td>1341.307000000000016</td>\n",
       "      <td>3151.707800000000134</td>\n",
       "      <td>2182.525477777777724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.002150416</td>\n",
       "      <td>-0.0060313176</td>\n",
       "      <td>0.0019761204</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.5408150690</td>\n",
       "      <td>1.447526614</td>\n",
       "      <td>-0.8766437152</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.783147496403011</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>-0.333334935854766</td>\n",
       "      <td>144.735782942484661</td>\n",
       "      <td>35.264464920571676</td>\n",
       "      <td>109.471318021912978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>157.711800000000011</td>\n",
       "      <td>157.709969999999998</td>\n",
       "      <td>157.70698999999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.210000000000001</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.364100000000001</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478929999999998</td>\n",
       "      <td>-40.476061999999999</td>\n",
       "      <td>-40.475116999999997</td>\n",
       "      <td>-40.498596999999997</td>\n",
       "      <td>6.468999999999999</td>\n",
       "      <td>1341.307000000000016</td>\n",
       "      <td>3151.707800000000134</td>\n",
       "      <td>2182.525477777777724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.133921</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.002150416</td>\n",
       "      <td>-0.0060313176</td>\n",
       "      <td>0.0019761204</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.5238136345</td>\n",
       "      <td>1.437932644</td>\n",
       "      <td>0.9063972942</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.783156685329616</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091947541112027</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>1.091947541112027</td>\n",
       "      <td>-0.333347258933468</td>\n",
       "      <td>144.736135830960848</td>\n",
       "      <td>35.264068916722060</td>\n",
       "      <td>109.472066914238823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>157.711800000000011</td>\n",
       "      <td>157.709969999999998</td>\n",
       "      <td>157.70698999999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.210000000000001</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.364100000000001</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478929999999998</td>\n",
       "      <td>-40.476061999999999</td>\n",
       "      <td>-40.475116999999997</td>\n",
       "      <td>-40.498596999999997</td>\n",
       "      <td>6.468999999999999</td>\n",
       "      <td>1341.307000000000016</td>\n",
       "      <td>3151.707800000000134</td>\n",
       "      <td>2182.525477777777724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.133922</td>\n",
       "      <td>-0.535689</td>\n",
       "      <td>1.011730843</td>\n",
       "      <td>1.4637511620</td>\n",
       "      <td>0.0002765748</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>-0.0126981359</td>\n",
       "      <td>1.085804158</td>\n",
       "      <td>0.0080009958</td>\n",
       "      <td>3</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>-0.5408150690</td>\n",
       "      <td>1.447526614</td>\n",
       "      <td>-0.8766437152</td>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>1.091946379133103</td>\n",
       "      <td>0.333351894767600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.472348641859767</td>\n",
       "      <td>70.527651358140233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  type                 rc_A                 rc_B  \\\n",
       "0  dsgdb9nsd_000001  1JHC  157.711800000000011  157.709969999999998   \n",
       "1  dsgdb9nsd_000001  2JHH  157.711800000000011  157.709969999999998   \n",
       "2  dsgdb9nsd_000001  2JHH  157.711800000000011  157.709969999999998   \n",
       "3  dsgdb9nsd_000001  2JHH  157.711800000000011  157.709969999999998   \n",
       "4  dsgdb9nsd_000001  1JHC  157.711800000000011  157.709969999999998   \n",
       "\n",
       "                 rc_C   mu               alpha    homo    lumo     gap  \\\n",
       "0  157.70698999999999  0.0  13.210000000000001 -0.3877  0.1171  0.5048   \n",
       "1  157.70698999999999  0.0  13.210000000000001 -0.3877  0.1171  0.5048   \n",
       "2  157.70698999999999  0.0  13.210000000000001 -0.3877  0.1171  0.5048   \n",
       "3  157.70698999999999  0.0  13.210000000000001 -0.3877  0.1171  0.5048   \n",
       "4  157.70698999999999  0.0  13.210000000000001 -0.3877  0.1171  0.5048   \n",
       "\n",
       "                   r2      zpve                  U0                   U  \\\n",
       "0  35.364100000000001  0.044749 -40.478929999999998 -40.476061999999999   \n",
       "1  35.364100000000001  0.044749 -40.478929999999998 -40.476061999999999   \n",
       "2  35.364100000000001  0.044749 -40.478929999999998 -40.476061999999999   \n",
       "3  35.364100000000001  0.044749 -40.478929999999998 -40.476061999999999   \n",
       "4  35.364100000000001  0.044749 -40.478929999999998 -40.476061999999999   \n",
       "\n",
       "                    H                   G                 Cv  \\\n",
       "0 -40.475116999999997 -40.498596999999997  6.468999999999999   \n",
       "1 -40.475116999999997 -40.498596999999997  6.468999999999999   \n",
       "2 -40.475116999999997 -40.498596999999997  6.468999999999999   \n",
       "3 -40.475116999999997 -40.498596999999997  6.468999999999999   \n",
       "4 -40.475116999999997 -40.498596999999997  6.468999999999999   \n",
       "\n",
       "              freqs_min             freqs_max            freqs_mean  linear  \\\n",
       "0  1341.307000000000016  3151.707800000000134  2182.525477777777724     1.0   \n",
       "1  1341.307000000000016  3151.707800000000134  2182.525477777777724     1.0   \n",
       "2  1341.307000000000016  3151.707800000000134  2182.525477777777724     1.0   \n",
       "3  1341.307000000000016  3151.707800000000134  2182.525477777777724     1.0   \n",
       "4  1341.307000000000016  3151.707800000000134  2182.525477777777724     1.0   \n",
       "\n",
       "   mulliken_min  mulliken_max  mulliken_atom_0  mulliken_atom_1          x_0  \\\n",
       "0     -0.535689      0.133923         0.133921        -0.535689  0.002150416   \n",
       "1     -0.535689      0.133923         0.133921         0.133922  0.002150416   \n",
       "2     -0.535689      0.133923         0.133921         0.133923  0.002150416   \n",
       "3     -0.535689      0.133923         0.133921         0.133923  0.002150416   \n",
       "4     -0.535689      0.133923         0.133922        -0.535689  1.011730843   \n",
       "\n",
       "            y_0           z_0  EN_x  RD_x           x_1          y_1  \\\n",
       "0 -0.0060313176  0.0019761204   2.2  0.43 -0.0126981359  1.085804158   \n",
       "1 -0.0060313176  0.0019761204   2.2  0.43  1.0117308430  1.463751162   \n",
       "2 -0.0060313176  0.0019761204   2.2  0.43 -0.5408150690  1.447526614   \n",
       "3 -0.0060313176  0.0019761204   2.2  0.43 -0.5238136345  1.437932644   \n",
       "4  1.4637511620  0.0002765748   2.2  0.43 -0.0126981359  1.085804158   \n",
       "\n",
       "            z_1  EN_y  RD_y           distance  EN_0  RD_0  hybri_0  EN_1  \\\n",
       "0  0.0080009958  2.55  0.82  1.091953059611900   2.2  0.43        0  2.55   \n",
       "1  0.0002765748  2.20  0.43  1.783119756038801   2.2  0.43        0  2.20   \n",
       "2 -0.8766437152  2.20  0.43  1.783147496403011   2.2  0.43        0  2.20   \n",
       "3  0.9063972942  2.20  0.43  1.783156685329616   2.2  0.43        0  2.20   \n",
       "4  0.0080009958  2.55  0.82  1.091951618581363   2.2  0.43        0  2.55   \n",
       "\n",
       "   RD_1  hybri_1  atom_index_closest_0  distance_closest_0   x_closest_0  \\\n",
       "0  0.82        3                     0   1.091953059611900 -0.0126981359   \n",
       "1  0.43        0                     0   1.091953059611900 -0.0126981359   \n",
       "2  0.43        0                     0   1.091953059611900 -0.0126981359   \n",
       "3  0.43        0                     0   1.091953059611900 -0.0126981359   \n",
       "4  0.82        3                     0   1.091951618581363 -0.0126981359   \n",
       "\n",
       "   y_closest_0   z_closest_0  atom_index_closest_1  distance_closest_1  \\\n",
       "0  1.085804158  0.0080009958                     3   1.091946379133103   \n",
       "1  1.085804158  0.0080009958                     0   1.091951618581363   \n",
       "2  1.085804158  0.0080009958                     0   1.091946379133103   \n",
       "3  1.085804158  0.0080009958                     0   1.091947541112027   \n",
       "4  1.085804158  0.0080009958                     3   1.091946379133103   \n",
       "\n",
       "    x_closest_1  y_closest_1   z_closest_1         distance_0  \\\n",
       "0 -0.5408150690  1.447526614 -0.8766437152  1.091953059611900   \n",
       "1 -0.0126981359  1.085804158  0.0080009958  1.091953059611900   \n",
       "2 -0.0126981359  1.085804158  0.0080009958  1.091953059611900   \n",
       "3 -0.0126981359  1.085804158  0.0080009958  1.091953059611900   \n",
       "4 -0.5408150690  1.447526614 -0.8766437152  1.091951618581363   \n",
       "\n",
       "          distance_1            cos_0_1                cos_0  \\\n",
       "0  1.091946379133103  0.333334935854766  179.999998792581749   \n",
       "1  1.091951618581363 -0.333287053439111  144.734230817948855   \n",
       "2  1.091946379133103 -0.333334935854766  144.735782942484661   \n",
       "3  1.091947541112027 -0.333347258933468  144.736135830960848   \n",
       "4  1.091946379133103  0.333351894767600                  NaN   \n",
       "\n",
       "                 cos_1                Angle  \n",
       "0  109.471318021912978   70.528681978087036  \n",
       "1   35.265822650766161  109.468408167182687  \n",
       "2   35.264464920571676  109.471318021912978  \n",
       "3   35.264068916722060  109.472066914238823  \n",
       "4  109.472348641859767   70.527651358140233  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepData(dataFrame):\n",
    "    dataFrame.drop([\"molecule_name\"], axis = 1)\n",
    "    a = pd.get_dummies(dataFrame.type)\n",
    "    dataFrame = pd.concat([dataFrame, a], axis = 'columns')\n",
    "    dataFrame = dataFrame.drop(\"type\", axis = 1)\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = prepData(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_final.drop([\"molecule_name\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = prepData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test_final.drop([\"molecule_name\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_regression(X, X_test, y, params, folds, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 45,\n",
    "          'min_child_samples': 79,\n",
    "          'min_data_in_leaf' : 100,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.2,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 1.0\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    84.807599999999994\n",
       "1   -11.257000000000000\n",
       "2   -11.254799999999999\n",
       "3   -11.254300000000001\n",
       "4    84.807400000000001\n",
       "Name: scalar_coupling_constant, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Aug  9 16:24:16 2019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l1: 1.15719\tvalid_1's l1: 1.35751\n",
      "[1000]\ttraining's l1: 1.05291\tvalid_1's l1: 1.31163\n",
      "[1500]\ttraining's l1: 0.989318\tvalid_1's l1: 1.28651\n",
      "[2000]\ttraining's l1: 0.94249\tvalid_1's l1: 1.26984\n",
      "[2500]\ttraining's l1: 0.907893\tvalid_1's l1: 1.26141\n",
      "[3000]\ttraining's l1: 0.878686\tvalid_1's l1: 1.25322\n",
      "Early stopping, best iteration is:\n",
      "[3049]\ttraining's l1: 0.876144\tvalid_1's l1: 1.25248\n",
      "Fold 2 started at Fri Aug  9 16:36:42 2019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l1: 1.10801\tvalid_1's l1: 1.41368\n",
      "[1000]\ttraining's l1: 1.00399\tvalid_1's l1: 1.33609\n",
      "[1500]\ttraining's l1: 0.943207\tvalid_1's l1: 1.29866\n",
      "[2000]\ttraining's l1: 0.900058\tvalid_1's l1: 1.27434\n",
      "[2500]\ttraining's l1: 0.865374\tvalid_1's l1: 1.25614\n",
      "[3000]\ttraining's l1: 0.835422\tvalid_1's l1: 1.24325\n",
      "[3500]\ttraining's l1: 0.811315\tvalid_1's l1: 1.23386\n",
      "[4000]\ttraining's l1: 0.790062\tvalid_1's l1: 1.22626\n",
      "[4500]\ttraining's l1: 0.770277\tvalid_1's l1: 1.21904\n",
      "[5000]\ttraining's l1: 0.752379\tvalid_1's l1: 1.21237\n",
      "[5500]\ttraining's l1: 0.73632\tvalid_1's l1: 1.20712\n",
      "[6000]\ttraining's l1: 0.72122\tvalid_1's l1: 1.20249\n",
      "[6500]\ttraining's l1: 0.707394\tvalid_1's l1: 1.1989\n",
      "[7000]\ttraining's l1: 0.694298\tvalid_1's l1: 1.19533\n",
      "[7500]\ttraining's l1: 0.681631\tvalid_1's l1: 1.19219\n",
      "[8000]\ttraining's l1: 0.669587\tvalid_1's l1: 1.18928\n",
      "[8500]\ttraining's l1: 0.658571\tvalid_1's l1: 1.18686\n",
      "[9000]\ttraining's l1: 0.648094\tvalid_1's l1: 1.18465\n",
      "[9500]\ttraining's l1: 0.637798\tvalid_1's l1: 1.18255\n",
      "[10000]\ttraining's l1: 0.628165\tvalid_1's l1: 1.18069\n",
      "[10500]\ttraining's l1: 0.618774\tvalid_1's l1: 1.17872\n",
      "[11000]\ttraining's l1: 0.60991\tvalid_1's l1: 1.177\n",
      "[11500]\ttraining's l1: 0.601347\tvalid_1's l1: 1.17532\n",
      "[12000]\ttraining's l1: 0.593145\tvalid_1's l1: 1.17413\n",
      "[12500]\ttraining's l1: 0.584958\tvalid_1's l1: 1.17326\n",
      "[13000]\ttraining's l1: 0.577228\tvalid_1's l1: 1.17174\n",
      "[13500]\ttraining's l1: 0.56964\tvalid_1's l1: 1.17058\n",
      "[14000]\ttraining's l1: 0.562525\tvalid_1's l1: 1.16971\n",
      "[14500]\ttraining's l1: 0.55522\tvalid_1's l1: 1.16828\n",
      "Early stopping, best iteration is:\n",
      "[14735]\ttraining's l1: 0.551925\tvalid_1's l1: 1.16796\n",
      "Fold 3 started at Fri Aug  9 17:40:39 2019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l1: 1.15232\tvalid_1's l1: 1.2646\n",
      "[1000]\ttraining's l1: 1.04099\tvalid_1's l1: 1.18807\n",
      "[1500]\ttraining's l1: 0.978656\tvalid_1's l1: 1.14978\n",
      "[2000]\ttraining's l1: 0.930163\tvalid_1's l1: 1.12152\n",
      "[2500]\ttraining's l1: 0.893758\tvalid_1's l1: 1.10214\n",
      "[3000]\ttraining's l1: 0.862979\tvalid_1's l1: 1.08647\n",
      "[3500]\ttraining's l1: 0.838746\tvalid_1's l1: 1.07642\n",
      "[4000]\ttraining's l1: 0.815996\tvalid_1's l1: 1.06659\n",
      "[4500]\ttraining's l1: 0.796238\tvalid_1's l1: 1.05897\n",
      "[5000]\ttraining's l1: 0.777631\tvalid_1's l1: 1.05231\n",
      "[5500]\ttraining's l1: 0.761329\tvalid_1's l1: 1.04698\n",
      "[6000]\ttraining's l1: 0.745875\tvalid_1's l1: 1.0419\n",
      "[6500]\ttraining's l1: 0.730886\tvalid_1's l1: 1.03655\n",
      "[7000]\ttraining's l1: 0.717211\tvalid_1's l1: 1.03225\n",
      "[7500]\ttraining's l1: 0.704443\tvalid_1's l1: 1.0285\n",
      "[8000]\ttraining's l1: 0.69211\tvalid_1's l1: 1.02409\n",
      "[8500]\ttraining's l1: 0.68055\tvalid_1's l1: 1.02067\n",
      "[9000]\ttraining's l1: 0.669829\tvalid_1's l1: 1.01789\n",
      "[9500]\ttraining's l1: 0.659454\tvalid_1's l1: 1.01491\n",
      "[10000]\ttraining's l1: 0.649707\tvalid_1's l1: 1.01283\n",
      "[10500]\ttraining's l1: 0.640094\tvalid_1's l1: 1.01043\n",
      "[11000]\ttraining's l1: 0.630912\tvalid_1's l1: 1.00849\n",
      "[11500]\ttraining's l1: 0.622424\tvalid_1's l1: 1.007\n",
      "[12000]\ttraining's l1: 0.613937\tvalid_1's l1: 1.005\n",
      "[12500]\ttraining's l1: 0.605683\tvalid_1's l1: 1.00335\n",
      "[13000]\ttraining's l1: 0.597897\tvalid_1's l1: 1.00182\n",
      "[13500]\ttraining's l1: 0.590161\tvalid_1's l1: 1.00018\n",
      "[14000]\ttraining's l1: 0.582767\tvalid_1's l1: 0.998512\n",
      "[14500]\ttraining's l1: 0.575426\tvalid_1's l1: 0.997228\n",
      "[15000]\ttraining's l1: 0.568272\tvalid_1's l1: 0.995709\n",
      "[15500]\ttraining's l1: 0.5616\tvalid_1's l1: 0.994546\n",
      "[16000]\ttraining's l1: 0.554889\tvalid_1's l1: 0.993316\n",
      "[16500]\ttraining's l1: 0.548443\tvalid_1's l1: 0.992356\n",
      "[17000]\ttraining's l1: 0.542136\tvalid_1's l1: 0.991269\n",
      "[17500]\ttraining's l1: 0.536011\tvalid_1's l1: 0.990304\n",
      "[18000]\ttraining's l1: 0.530039\tvalid_1's l1: 0.989327\n",
      "[18500]\ttraining's l1: 0.524206\tvalid_1's l1: 0.9884\n",
      "[19000]\ttraining's l1: 0.518444\tvalid_1's l1: 0.987425\n",
      "[19500]\ttraining's l1: 0.512828\tvalid_1's l1: 0.986658\n",
      "[20000]\ttraining's l1: 0.507449\tvalid_1's l1: 0.985869\n",
      "[20500]\ttraining's l1: 0.502109\tvalid_1's l1: 0.985063\n",
      "[21000]\ttraining's l1: 0.496978\tvalid_1's l1: 0.98439\n",
      "[21500]\ttraining's l1: 0.49173\tvalid_1's l1: 0.983527\n",
      "[22000]\ttraining's l1: 0.486641\tvalid_1's l1: 0.982713\n",
      "[22500]\ttraining's l1: 0.481834\tvalid_1's l1: 0.982095\n",
      "[23000]\ttraining's l1: 0.477125\tvalid_1's l1: 0.981563\n",
      "[23500]\ttraining's l1: 0.472497\tvalid_1's l1: 0.98102\n",
      "[24000]\ttraining's l1: 0.467866\tvalid_1's l1: 0.980277\n",
      "[24500]\ttraining's l1: 0.463318\tvalid_1's l1: 0.979727\n",
      "[25000]\ttraining's l1: 0.458808\tvalid_1's l1: 0.979055\n",
      "[25500]\ttraining's l1: 0.454352\tvalid_1's l1: 0.978514\n",
      "[26000]\ttraining's l1: 0.450008\tvalid_1's l1: 0.977989\n",
      "[26500]\ttraining's l1: 0.445811\tvalid_1's l1: 0.977397\n",
      "[27000]\ttraining's l1: 0.441572\tvalid_1's l1: 0.976828\n",
      "[27500]\ttraining's l1: 0.437566\tvalid_1's l1: 0.976386\n",
      "[28000]\ttraining's l1: 0.433494\tvalid_1's l1: 0.975917\n",
      "[28500]\ttraining's l1: 0.429496\tvalid_1's l1: 0.975394\n",
      "[29000]\ttraining's l1: 0.42561\tvalid_1's l1: 0.974968\n",
      "[29500]\ttraining's l1: 0.421799\tvalid_1's l1: 0.97456\n",
      "[30000]\ttraining's l1: 0.418086\tvalid_1's l1: 0.974158\n",
      "[30500]\ttraining's l1: 0.414393\tvalid_1's l1: 0.973726\n",
      "[31000]\ttraining's l1: 0.410743\tvalid_1's l1: 0.973366\n",
      "[31500]\ttraining's l1: 0.407135\tvalid_1's l1: 0.973069\n",
      "[32000]\ttraining's l1: 0.403616\tvalid_1's l1: 0.972728\n",
      "[32500]\ttraining's l1: 0.400117\tvalid_1's l1: 0.972365\n",
      "[33000]\ttraining's l1: 0.396725\tvalid_1's l1: 0.972013\n",
      "[33500]\ttraining's l1: 0.393316\tvalid_1's l1: 0.971626\n",
      "[34000]\ttraining's l1: 0.389992\tvalid_1's l1: 0.971359\n",
      "[34500]\ttraining's l1: 0.386632\tvalid_1's l1: 0.970917\n",
      "[35000]\ttraining's l1: 0.383389\tvalid_1's l1: 0.970625\n",
      "[35500]\ttraining's l1: 0.380178\tvalid_1's l1: 0.970314\n",
      "[36000]\ttraining's l1: 0.377023\tvalid_1's l1: 0.969925\n",
      "[36500]\ttraining's l1: 0.373942\tvalid_1's l1: 0.969628\n",
      "[37000]\ttraining's l1: 0.37088\tvalid_1's l1: 0.969339\n",
      "[37500]\ttraining's l1: 0.367906\tvalid_1's l1: 0.969063\n",
      "[38000]\ttraining's l1: 0.364879\tvalid_1's l1: 0.968837\n",
      "[38500]\ttraining's l1: 0.361933\tvalid_1's l1: 0.968587\n",
      "[39000]\ttraining's l1: 0.359012\tvalid_1's l1: 0.968406\n",
      "Early stopping, best iteration is:\n",
      "[39253]\ttraining's l1: 0.35757\tvalid_1's l1: 0.968203\n",
      "Fold 4 started at Fri Aug  9 20:31:03 2019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l1: 1.16985\tvalid_1's l1: 1.18832\n",
      "[1000]\ttraining's l1: 1.05602\tvalid_1's l1: 1.10932\n",
      "[1500]\ttraining's l1: 0.992325\tvalid_1's l1: 1.06902\n",
      "[2000]\ttraining's l1: 0.946819\tvalid_1's l1: 1.04442\n",
      "[2500]\ttraining's l1: 0.910748\tvalid_1's l1: 1.02652\n",
      "[3000]\ttraining's l1: 0.880187\tvalid_1's l1: 1.01139\n",
      "[3500]\ttraining's l1: 0.853953\tvalid_1's l1: 1.00024\n",
      "[4000]\ttraining's l1: 0.830801\tvalid_1's l1: 0.990764\n",
      "[4500]\ttraining's l1: 0.81009\tvalid_1's l1: 0.982799\n",
      "[5000]\ttraining's l1: 0.791415\tvalid_1's l1: 0.9761\n",
      "[5500]\ttraining's l1: 0.773918\tvalid_1's l1: 0.96972\n",
      "[6000]\ttraining's l1: 0.758163\tvalid_1's l1: 0.964284\n",
      "[6500]\ttraining's l1: 0.742704\tvalid_1's l1: 0.959128\n",
      "[7000]\ttraining's l1: 0.728884\tvalid_1's l1: 0.95508\n",
      "[7500]\ttraining's l1: 0.716519\tvalid_1's l1: 0.951835\n",
      "[8000]\ttraining's l1: 0.704151\tvalid_1's l1: 0.948157\n",
      "[8500]\ttraining's l1: 0.69253\tvalid_1's l1: 0.944811\n",
      "[9000]\ttraining's l1: 0.681039\tvalid_1's l1: 0.941385\n",
      "[9500]\ttraining's l1: 0.670537\tvalid_1's l1: 0.938843\n",
      "[10000]\ttraining's l1: 0.660258\tvalid_1's l1: 0.936136\n",
      "[10500]\ttraining's l1: 0.650406\tvalid_1's l1: 0.933681\n",
      "[11000]\ttraining's l1: 0.640906\tvalid_1's l1: 0.931276\n",
      "[11500]\ttraining's l1: 0.631943\tvalid_1's l1: 0.929176\n",
      "[12000]\ttraining's l1: 0.623217\tvalid_1's l1: 0.927255\n",
      "[12500]\ttraining's l1: 0.614919\tvalid_1's l1: 0.925629\n",
      "[13000]\ttraining's l1: 0.606862\tvalid_1's l1: 0.923879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13500]\ttraining's l1: 0.599157\tvalid_1's l1: 0.922468\n",
      "[14000]\ttraining's l1: 0.591284\tvalid_1's l1: 0.920584\n",
      "[14500]\ttraining's l1: 0.583927\tvalid_1's l1: 0.919058\n",
      "[15000]\ttraining's l1: 0.576784\tvalid_1's l1: 0.917701\n",
      "[15500]\ttraining's l1: 0.569884\tvalid_1's l1: 0.916377\n",
      "[16000]\ttraining's l1: 0.562995\tvalid_1's l1: 0.914995\n",
      "[16500]\ttraining's l1: 0.556206\tvalid_1's l1: 0.913554\n",
      "[17000]\ttraining's l1: 0.549817\tvalid_1's l1: 0.91234\n",
      "[17500]\ttraining's l1: 0.54365\tvalid_1's l1: 0.911374\n",
      "[18000]\ttraining's l1: 0.537504\tvalid_1's l1: 0.910287\n",
      "[18500]\ttraining's l1: 0.531467\tvalid_1's l1: 0.909208\n",
      "[19000]\ttraining's l1: 0.52563\tvalid_1's l1: 0.908372\n",
      "[19500]\ttraining's l1: 0.520088\tvalid_1's l1: 0.907472\n",
      "[20000]\ttraining's l1: 0.514618\tvalid_1's l1: 0.906715\n",
      "[20500]\ttraining's l1: 0.509178\tvalid_1's l1: 0.905893\n",
      "[21000]\ttraining's l1: 0.503812\tvalid_1's l1: 0.904997\n",
      "[21500]\ttraining's l1: 0.498413\tvalid_1's l1: 0.90406\n",
      "[22000]\ttraining's l1: 0.49339\tvalid_1's l1: 0.903274\n",
      "[22500]\ttraining's l1: 0.488288\tvalid_1's l1: 0.902559\n",
      "[23000]\ttraining's l1: 0.483477\tvalid_1's l1: 0.901992\n",
      "[23500]\ttraining's l1: 0.478668\tvalid_1's l1: 0.901455\n",
      "[24000]\ttraining's l1: 0.473847\tvalid_1's l1: 0.90068\n",
      "[24500]\ttraining's l1: 0.469236\tvalid_1's l1: 0.90014\n",
      "[25000]\ttraining's l1: 0.464785\tvalid_1's l1: 0.899545\n",
      "[25500]\ttraining's l1: 0.460275\tvalid_1's l1: 0.898818\n",
      "[26000]\ttraining's l1: 0.455865\tvalid_1's l1: 0.898265\n",
      "[26500]\ttraining's l1: 0.451565\tvalid_1's l1: 0.897692\n",
      "[27000]\ttraining's l1: 0.447227\tvalid_1's l1: 0.897107\n",
      "[27500]\ttraining's l1: 0.443086\tvalid_1's l1: 0.896636\n",
      "[28000]\ttraining's l1: 0.439009\tvalid_1's l1: 0.896048\n",
      "[28500]\ttraining's l1: 0.43491\tvalid_1's l1: 0.895528\n",
      "[29000]\ttraining's l1: 0.430988\tvalid_1's l1: 0.895076\n",
      "[29500]\ttraining's l1: 0.427041\tvalid_1's l1: 0.894464\n",
      "[30000]\ttraining's l1: 0.423178\tvalid_1's l1: 0.89395\n",
      "[30500]\ttraining's l1: 0.419354\tvalid_1's l1: 0.893385\n",
      "[31000]\ttraining's l1: 0.415726\tvalid_1's l1: 0.893114\n",
      "[31500]\ttraining's l1: 0.412044\tvalid_1's l1: 0.892651\n",
      "[32000]\ttraining's l1: 0.408503\tvalid_1's l1: 0.892255\n",
      "[32500]\ttraining's l1: 0.404996\tvalid_1's l1: 0.891859\n",
      "[33000]\ttraining's l1: 0.401491\tvalid_1's l1: 0.891455\n",
      "[33500]\ttraining's l1: 0.398062\tvalid_1's l1: 0.891064\n",
      "[34000]\ttraining's l1: 0.394692\tvalid_1's l1: 0.890684\n",
      "[34500]\ttraining's l1: 0.391295\tvalid_1's l1: 0.890341\n",
      "[35000]\ttraining's l1: 0.388061\tvalid_1's l1: 0.89013\n",
      "[35500]\ttraining's l1: 0.384885\tvalid_1's l1: 0.889836\n",
      "[36000]\ttraining's l1: 0.381684\tvalid_1's l1: 0.889486\n",
      "[36500]\ttraining's l1: 0.378518\tvalid_1's l1: 0.889212\n",
      "[37000]\ttraining's l1: 0.375298\tvalid_1's l1: 0.88877\n",
      "[37500]\ttraining's l1: 0.372153\tvalid_1's l1: 0.888394\n",
      "[38000]\ttraining's l1: 0.369182\tvalid_1's l1: 0.888148\n",
      "[38500]\ttraining's l1: 0.366182\tvalid_1's l1: 0.887869\n",
      "[39000]\ttraining's l1: 0.363216\tvalid_1's l1: 0.887587\n",
      "[39500]\ttraining's l1: 0.360285\tvalid_1's l1: 0.887347\n",
      "[40000]\ttraining's l1: 0.35739\tvalid_1's l1: 0.887099\n",
      "[40500]\ttraining's l1: 0.354549\tvalid_1's l1: 0.886841\n",
      "[41000]\ttraining's l1: 0.351759\tvalid_1's l1: 0.886603\n",
      "Early stopping, best iteration is:\n",
      "[41172]\ttraining's l1: 0.35082\tvalid_1's l1: 0.886483\n",
      "Fold 5 started at Fri Aug  9 23:29:53 2019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l1: 1.1718\tvalid_1's l1: 1.17525\n",
      "[1000]\ttraining's l1: 1.06763\tvalid_1's l1: 1.10252\n",
      "[1500]\ttraining's l1: 1.0035\tvalid_1's l1: 1.06172\n",
      "[2000]\ttraining's l1: 0.958257\tvalid_1's l1: 1.03501\n",
      "[2500]\ttraining's l1: 0.920684\tvalid_1's l1: 1.01467\n",
      "[3000]\ttraining's l1: 0.891622\tvalid_1's l1: 1.00184\n",
      "[3500]\ttraining's l1: 0.865872\tvalid_1's l1: 0.989864\n",
      "[4000]\ttraining's l1: 0.842798\tvalid_1's l1: 0.980149\n",
      "[4500]\ttraining's l1: 0.822029\tvalid_1's l1: 0.971787\n",
      "[5000]\ttraining's l1: 0.803142\tvalid_1's l1: 0.964751\n",
      "[5500]\ttraining's l1: 0.785974\tvalid_1's l1: 0.958372\n",
      "[6000]\ttraining's l1: 0.770193\tvalid_1's l1: 0.953275\n",
      "[6500]\ttraining's l1: 0.755644\tvalid_1's l1: 0.94902\n",
      "[7000]\ttraining's l1: 0.741737\tvalid_1's l1: 0.945176\n",
      "[7500]\ttraining's l1: 0.72849\tvalid_1's l1: 0.940841\n",
      "[8000]\ttraining's l1: 0.716199\tvalid_1's l1: 0.936934\n",
      "[8500]\ttraining's l1: 0.704703\tvalid_1's l1: 0.934033\n",
      "[9000]\ttraining's l1: 0.693408\tvalid_1's l1: 0.931087\n",
      "[9500]\ttraining's l1: 0.682763\tvalid_1's l1: 0.928515\n",
      "[10000]\ttraining's l1: 0.672401\tvalid_1's l1: 0.925902\n",
      "[10500]\ttraining's l1: 0.662814\tvalid_1's l1: 0.923599\n",
      "[11000]\ttraining's l1: 0.653358\tvalid_1's l1: 0.921463\n",
      "[11500]\ttraining's l1: 0.644164\tvalid_1's l1: 0.919434\n",
      "[12000]\ttraining's l1: 0.63522\tvalid_1's l1: 0.917277\n",
      "[12500]\ttraining's l1: 0.626908\tvalid_1's l1: 0.915699\n",
      "[13000]\ttraining's l1: 0.6188\tvalid_1's l1: 0.914124\n",
      "[13500]\ttraining's l1: 0.610824\tvalid_1's l1: 0.912408\n",
      "[14000]\ttraining's l1: 0.60281\tvalid_1's l1: 0.91073\n",
      "[14500]\ttraining's l1: 0.595556\tvalid_1's l1: 0.909488\n",
      "[15000]\ttraining's l1: 0.588438\tvalid_1's l1: 0.908419\n",
      "[15500]\ttraining's l1: 0.581494\tvalid_1's l1: 0.907312\n",
      "[16000]\ttraining's l1: 0.574648\tvalid_1's l1: 0.906089\n",
      "[16500]\ttraining's l1: 0.568038\tvalid_1's l1: 0.90481\n",
      "[17000]\ttraining's l1: 0.561517\tvalid_1's l1: 0.903858\n",
      "[17500]\ttraining's l1: 0.555273\tvalid_1's l1: 0.902627\n",
      "[18000]\ttraining's l1: 0.549049\tvalid_1's l1: 0.901494\n",
      "[18500]\ttraining's l1: 0.543051\tvalid_1's l1: 0.900505\n",
      "[19000]\ttraining's l1: 0.537216\tvalid_1's l1: 0.89958\n",
      "[19500]\ttraining's l1: 0.531352\tvalid_1's l1: 0.898705\n",
      "[20000]\ttraining's l1: 0.525526\tvalid_1's l1: 0.897818\n",
      "[20500]\ttraining's l1: 0.520095\tvalid_1's l1: 0.897149\n",
      "[21000]\ttraining's l1: 0.514723\tvalid_1's l1: 0.896407\n",
      "[21500]\ttraining's l1: 0.509513\tvalid_1's l1: 0.895724\n",
      "[22000]\ttraining's l1: 0.50444\tvalid_1's l1: 0.89506\n",
      "[22500]\ttraining's l1: 0.499372\tvalid_1's l1: 0.894599\n",
      "[23000]\ttraining's l1: 0.494436\tvalid_1's l1: 0.893884\n",
      "[23500]\ttraining's l1: 0.489527\tvalid_1's l1: 0.893392\n",
      "[24000]\ttraining's l1: 0.484689\tvalid_1's l1: 0.892664\n",
      "[24500]\ttraining's l1: 0.479998\tvalid_1's l1: 0.892029\n",
      "[25000]\ttraining's l1: 0.475465\tvalid_1's l1: 0.891523\n",
      "[25500]\ttraining's l1: 0.470896\tvalid_1's l1: 0.890738\n",
      "[26000]\ttraining's l1: 0.466398\tvalid_1's l1: 0.890101\n",
      "[26500]\ttraining's l1: 0.461995\tvalid_1's l1: 0.889509\n",
      "[27000]\ttraining's l1: 0.457717\tvalid_1's l1: 0.88915\n",
      "[27500]\ttraining's l1: 0.453496\tvalid_1's l1: 0.888636\n",
      "[28000]\ttraining's l1: 0.449287\tvalid_1's l1: 0.888062\n",
      "[28500]\ttraining's l1: 0.445148\tvalid_1's l1: 0.887594\n",
      "[29000]\ttraining's l1: 0.441147\tvalid_1's l1: 0.887171\n",
      "[29500]\ttraining's l1: 0.437223\tvalid_1's l1: 0.886716\n",
      "[30000]\ttraining's l1: 0.433337\tvalid_1's l1: 0.886328\n",
      "[30500]\ttraining's l1: 0.429473\tvalid_1's l1: 0.885994\n",
      "[31000]\ttraining's l1: 0.42569\tvalid_1's l1: 0.885637\n",
      "[31500]\ttraining's l1: 0.421953\tvalid_1's l1: 0.885256\n",
      "[32000]\ttraining's l1: 0.418234\tvalid_1's l1: 0.884973\n",
      "[32500]\ttraining's l1: 0.414649\tvalid_1's l1: 0.884516\n",
      "[33000]\ttraining's l1: 0.411105\tvalid_1's l1: 0.88424\n",
      "[33500]\ttraining's l1: 0.407651\tvalid_1's l1: 0.884036\n",
      "[34000]\ttraining's l1: 0.404238\tvalid_1's l1: 0.883595\n",
      "[34500]\ttraining's l1: 0.400857\tvalid_1's l1: 0.883264\n",
      "[35000]\ttraining's l1: 0.397496\tvalid_1's l1: 0.882964\n",
      "[35500]\ttraining's l1: 0.394199\tvalid_1's l1: 0.882687\n",
      "[36000]\ttraining's l1: 0.390978\tvalid_1's l1: 0.8824\n",
      "Early stopping, best iteration is:\n",
      "[36175]\ttraining's l1: 0.389816\tvalid_1's l1: 0.882279\n",
      "CV mean score: 1.0315, std: 0.1515.\n"
     ]
    }
   ],
   "source": [
    "results = train_model_regression(X_final, X_test_final, y, params=params, folds = folds, model_type = 'lgb', eval_metric = 'mae', plot_feature_importance=False,\n",
    "                      verbose = 500, early_stopping_rounds=100, n_estimators = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.rename(columns={0:'scalar_coupling_constant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.061438659098263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169.169296035380398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.321244125022561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166.903430897654260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.303294298876569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scalar_coupling_constant\n",
       "0        15.061438659098263\n",
       "1       169.169296035380398\n",
       "2         6.321244125022561\n",
       "3       166.903430897654260\n",
       "4        14.303294298876569"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.drop(\"scalar_coupling_constant\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalised_Prediction = pd.concat([sub, prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>15.061438659098263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>169.169296035380398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>6.321244125022561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>166.903430897654260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>14.303294298876569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  scalar_coupling_constant\n",
       "0  4658147        15.061438659098263\n",
       "1  4658148       169.169296035380398\n",
       "2  4658149         6.321244125022561\n",
       "3  4658150       166.903430897654260\n",
       "4  4658151        14.303294298876569"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finalised_Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Finalised_Prediction.to_csv('QM9_submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
