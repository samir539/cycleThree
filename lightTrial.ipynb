{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "structures = pd.read_csv(r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\structures.csv\", dtype={'atom_index': np.int8})\n",
    "train = pd.read_csv(r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\train.csv\",index_col=0)\n",
    "test = pd.read_csv(r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\test.csv\")\n",
    "sub = pd.read_csv(r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807599999999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254799999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807400000000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "id                                                       \n",
       "0   dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "    scalar_coupling_constant  \n",
       "id                            \n",
       "0         84.807599999999994  \n",
       "1        -11.257000000000000  \n",
       "2        -11.254799999999999  \n",
       "3        -11.254300000000001  \n",
       "4         84.807400000000001  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size reduction for testing \n",
    "size = round(0.10*train.shape[0])\n",
    "train = train[:size]\n",
    "test = test[:size]\n",
    "sub = sub[:size]\n",
    "structures = structures[:size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [00:00<00:00, 3678233.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:14<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting and condensing bonds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [00:08<00:00, 283249.92it/s]\n",
      "100%|██████████| 2358657/2358657 [00:11<00:00, 204838.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating hybridization....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [01:18<00:00, 29996.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pi bonds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358657/2358657 [01:14<00:00, 31510.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# libraries required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def reduce_memory(df, verbose=True):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe required to decrease the memory usage\n",
    "    :param: verbose - show logging output if 'Ture'\n",
    "\n",
    "    Goal: Reduce the memory usage by decreasing the type of the value if applicable\n",
    "\n",
    "    Return: original dataframe with lower memory usage\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int64', 'int16', 'int32', 'float64', 'float32', 'float16']\n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_memory, 100 * (start_memory - end_memory) / start_memory))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def struc1_merge(df1, df2, index):\n",
    "    \"\"\"\n",
    "    :param: df1 - training data\n",
    "    :param: df2 - structure data after being added electronegativity, radius, bond_lengths, hybridization, surrounding atoms (bonds),\n",
    "            position info. (x, y, z)\n",
    "    :param: index - atom_index in the coupling\n",
    "\n",
    "    Goal: Merge original training dataframe with processed structure data to form a new dataframe for further training process\n",
    "\n",
    "    Return: Merged dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    struc1_train_merge = pd.merge(df1, df2, how='left',\n",
    "                                  left_on=['molecule_name', f'atom_index_{index}', f'atom_{index}', f'x_{index}', f'y_{index}', f'z_{index}'],\n",
    "                                  right_on=['molecule_name', 'atom_index', 'atom', 'x', 'y', 'z'])\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.drop(['n_bonds'], axis=1)\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.rename(columns={'EN': f'EN_{index}',\n",
    "                                                            'RD': f'RD_{index}',\n",
    "                                                            'bond_lengths': f'bond_lengths_{index}',\n",
    "                                                            'hybri': f'hybri_{index}',\n",
    "                                                            'bonds': f'bonds_{index}',\n",
    "                                                            'pi_bonds': f'pi_bonds_{index}'})\n",
    "    \n",
    "    return struc1_train_merge\n",
    "\n",
    "\n",
    "def n_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structure.csv from local data\n",
    "    \n",
    "    Goal: Calculate the number of bonds for each molecule.\n",
    "\n",
    "    Return: Structure dataframe with number of bonds (n_bonds) and lists consisting of indexes of connecting atoms (bonds)\n",
    "    \"\"\"\n",
    "\n",
    "    i_atom = structures['atom_index'].values\n",
    "    p = structures[['x', 'y', 'z']].values\n",
    "    p_compare = p\n",
    "    m = structures['molecule_name'].values\n",
    "    m_compare = m\n",
    "    r = structures['RD'].values\n",
    "    r_compare = r\n",
    "\n",
    "    source_row = np.arange(len(structures))\n",
    "    max_atoms = 28\n",
    "\n",
    "    bonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\n",
    "    bond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n",
    "\n",
    "    print('Calculating bonds')\n",
    "\n",
    "    for i in tqdm(range(max_atoms-1)):\n",
    "        p_compare = np.roll(p_compare, -1, axis=0)\n",
    "        m_compare = np.roll(m_compare, -1, axis=0)\n",
    "        r_compare = np.roll(r_compare, -1, axis=0)\n",
    "\n",
    "        mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n",
    "        dists = np.linalg.norm(p - p_compare, axis=1) * mask\n",
    "        r_bond = r + r_compare\n",
    "\n",
    "        bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n",
    "\n",
    "        source_row = source_row\n",
    "        target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n",
    "\n",
    "        source_atom = i_atom\n",
    "        target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n",
    "\n",
    "        bonds[(source_row, target_atom)] = bond\n",
    "        bonds[(target_row, source_atom)] = bond\n",
    "        bond_dists[(source_row, target_atom)] = dists\n",
    "        bond_dists[(target_row, source_atom)] = dists\n",
    "\n",
    "    bonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\n",
    "    bonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\n",
    "    bond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\n",
    "    bond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n",
    "\n",
    "    print('Counting and condensing bonds')\n",
    "\n",
    "    bonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\n",
    "    bond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\n",
    "    n_bonds = [len(x) for x in bonds_numeric]\n",
    "\n",
    "    #bond_data = {'bond_' + str(i):col for i, col in enumerate(np.transpose(bonds))}\n",
    "    #bond_data.update({'bonds_numeric':bonds_numeric, 'n_bonds':n_bonds})\n",
    "\n",
    "    bond_data = {'bonds':bonds_numeric, 'n_bonds':n_bonds, 'bond_lengths':bond_lengths}\n",
    "    bond_df = pd.DataFrame(bond_data)\n",
    "    structures = structures.join(bond_df)\n",
    "    \n",
    "    return structures\n",
    "\n",
    "\n",
    "def struc_merge(df, struc, index):\n",
    "    \"\"\"\n",
    "    :param: df - The dataframe to be merged with structure data\n",
    "    :param: struc - structure data\n",
    "    :param: index - index of atom in the coupling\n",
    "\n",
    "    Goal: Merger two dataframe.\n",
    "\n",
    "    Return: a new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge train and structures data based on the atom index\n",
    "    df_struc = pd.merge(df, struc, how='left', \n",
    "                        left_on=['molecule_name', f'atom_index_{index}'], \n",
    "                        right_on=['molecule_name', 'atom_index'])\n",
    "\n",
    "    # Drop the atom index column\n",
    "    df_struc = df_struc.drop('atom_index', axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    df_struc = df_struc.rename(columns={'atom': f'atom_{index}',\n",
    "                                        'x': f'x_{index}',\n",
    "                                        'y': f'y_{index}',\n",
    "                                        'z': f'z_{index}'})\n",
    "\n",
    "    return df_struc\n",
    "\n",
    "\n",
    "def distance(df, structures):\n",
    "    \"\"\"\n",
    "    :param: df - Data that need to calculate distance\n",
    "\n",
    "    Goal: Calculate the distance between two spins\n",
    "\n",
    "    Return: DataFrame with distance added\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy of  the data for avoiding changing the original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Merge data\n",
    "    df_copy = struc_merge(df_copy, structures, 0)\n",
    "    df_copy = struc_merge(df_copy, structures, 1)\n",
    "\n",
    "    # This block for calculating the distance between two spins\n",
    "    df_p_0 = df_copy[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df_copy[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "    df_copy['distance'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def hybridization(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate each hybridization in the structures data\n",
    "\n",
    "    Return: structure data with hybridization column added\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Calculating hybridization....')\n",
    "    \n",
    "    # 'C' has different types of hybridizations with different number of bonds.\n",
    "    # '4' for four bonds\n",
    "    hybri_dict = {'C': {'4': 3, '3': 2, '2': 2, '1': 0},\n",
    "                  'N': {'4': 0, '3': 3, '2': 2, '1': 1},\n",
    "                  'O': {'2': 2, '1': 1},\n",
    "                  'H': {'1': 0},\n",
    "                  'F': {'1': 0}}\n",
    "                # 3 bonds- sp3, 2 - sp2, 1 - sp\n",
    "    \n",
    "    hybri = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        hybri.append(hybri_dict[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "    \n",
    "    structures['hybri'] = hybri\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def pi_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate the number of pi_bonds for each atom\n",
    "\n",
    "    Return: structures with pi_bonds column added\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Calculating pi bonds....')\n",
    "    \n",
    "    # The number of atoms connecting to an atom is related with the number of pi bonds.\n",
    "    # Eg: In 'C', if there are 4 bonds around, then the number of pi bonds is 0.\n",
    "    pi_bond = {'C': {'4': 0, '2': 2, '3': 1},\n",
    "               'N': {'4': 0, '3': 0, '2': 1, '1': 2},\n",
    "               'O': {'1': 1, '2': 0},\n",
    "               'H': {'1': 0},\n",
    "               'F': {'1': 0}}\n",
    "\n",
    "    pi_bond_ = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        pi_bond_.append(pi_bond[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "\n",
    "    structures['pi_bonds'] = pi_bond_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def electronegativity(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an electrinegativity for each atom\n",
    "\n",
    "    Return: structures with electrineativity column added\n",
    "    \"\"\"\n",
    "    \n",
    "    electronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n",
    "    en_ = [electronegativity[x] for x in tqdm(atom_name)]\n",
    "\n",
    "    structures['EN'] = en_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def radius(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an radius for each atom\n",
    "\n",
    "    Return: structures with radius column added\n",
    "    \"\"\"\n",
    "    \n",
    "    atomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n",
    "\n",
    "    fudge_factor = 0.05\n",
    "    atomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\n",
    "    rd_ = [atomic_radius[x] for x in atom_name]\n",
    "\n",
    "    structures['RD'] = rd_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    \"\"\"\n",
    "    :param: df_1 - train data\n",
    "    :param: df_2 - structure data\n",
    "    :param: atom_ind - atom index in coupling\n",
    "\n",
    "    Goal: Merge two dataframe for further using\n",
    "\n",
    "    Return: A new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_closest(df_train):\n",
    "    df_temp=df_train.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"distance\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"distance\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df_train = map_atom_info(df_train,df_temp, atom_idx)\n",
    "        df_train = df_train.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                            'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                            'x_closest': f'x_closest_{atom_idx}',\n",
    "                                            'y_closest': f'y_closest_{atom_idx}',\n",
    "                                            'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def add_cos_features(df):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe containing necessary data for calculating the cosine value\n",
    "\n",
    "    Goal: Calculating cosine value\n",
    "\n",
    "    Return: dataframe with cosine data added\n",
    "    \"\"\"\n",
    "\n",
    "    # The modulus of the \n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    \n",
    "    # Unit vector along each direction\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    \n",
    "    # Ratio between the difference along each direction to the distance\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"distance\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"distance\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"distance\"]\n",
    "\n",
    "    # Cosine of each component\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "\n",
    "    # Angle for each component\n",
    "    df[\"Angle\"] = df[\"cos_0_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_0\"] = df[\"cos_0\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_1\"] = df[\"cos_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_path = r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\train.csv\"\n",
    "structures_path = r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\structures.csv\"\n",
    "test_path = r\"\\\\icnas1.cc.ic.ac.uk\\sc9018\\Desktop\\machineLearning19\\predicting properties\\test.csv\"\n",
    "\n",
    "# read data from local address\n",
    "train_df_full = pd.read_csv(train_path, index_col=0)\n",
    "structures_df_full = pd.read_csv(structures_path, dtype={'atom_index': np.int8})\n",
    "test_df_full = pd.read_csv(test_path)\n",
    "\n",
    "# Add distance feature to the test and trin data\n",
    "train_df = distance(train_df_full, structures_df_full)\n",
    "test_df = distance(test_df_full, structures_df_full)\n",
    "\n",
    "# ndarray with names of each atom in the structures csv\n",
    "atom = structures_df_full['atom'].values\n",
    "\n",
    "# Add electronegativity and radius colmun to the structures csv\n",
    "structures = electronegativity(atom, structures_df_full)\n",
    "structures = radius(atom, structures)\n",
    "\n",
    "# Add number of bonds and connecting atoms columns\n",
    "structures = n_bonds(structures)\n",
    "\n",
    "# Add hybridization column\n",
    "structures = hybridization(structures)\n",
    "\n",
    "# Add pi_bonds column\n",
    "structures = pi_bonds(structures)\n",
    "\n",
    "# Merge structures data and train data\n",
    "struc_train = struc1_merge(train_df, structures, 0)\n",
    "struc_train = struc1_merge(struc_train, structures, 1)\n",
    "\n",
    "struc_train = struc_train.drop(['atom_index_x', 'atom_x', 'x_x', 'y_x', 'z_x',\n",
    "                                'atom_index_y', 'atom_y','x_y', 'y_y', 'z_y'], axis=1)\n",
    "\n",
    "# Add bond angle column\n",
    "struc_train = create_closest(struc_train)\n",
    "struc_train = add_cos_features(struc_train)\n",
    "\n",
    "# The list of type for further training\n",
    "type_list = list(struc_train['type'].unique())\n",
    "\n",
    "# Drop the target column for training\n",
    "y = struc_train['scalar_coupling_constant']\n",
    "struc_train = struc_train.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "# Select features for training\n",
    "X = struc_train[['molecule_name',\n",
    "                           'type',\n",
    "                           'distance',\n",
    "                           'EN_0',\n",
    "                           'RD_0',\n",
    "                           'hybri_0',\n",
    "                           'pi_bonds_0',\n",
    "                           'EN_1',\n",
    "                           'RD_1',\n",
    "                           'hybri_1',\n",
    "                           'pi_bonds_1',\n",
    "                           'Angle']]\n",
    "\n",
    "struc_test = struc1_merge(test_df, structures, 0)\n",
    "struc_test = struc1_merge(struc_test, structures, 1)\n",
    "\n",
    "struc_test = struc_test.drop(['atom_index_x', 'atom_x', 'x_x', 'y_x', 'z_x',\n",
    "                                'atom_index_y', 'atom_y','x_y', 'y_y', 'z_y'], axis=1)\n",
    "\n",
    "\n",
    "struc_test = create_closest(struc_test)\n",
    "struc_test = add_cos_features(struc_test)\n",
    "\n",
    "# The list of type for further training\n",
    "type_list = list(struc_test['type'].unique())\n",
    "\n",
    "\n",
    "# Select features for training\n",
    "X_test = struc_test[['molecule_name',\n",
    "                           'type',\n",
    "                           'distance',\n",
    "                           'EN_0',\n",
    "                           'RD_0',\n",
    "                           'hybri_0',\n",
    "                           'pi_bonds_0',\n",
    "                           'EN_1',\n",
    "                           'RD_1',\n",
    "                           'hybri_1',\n",
    "                           'pi_bonds_1',\n",
    "                           'Angle']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(dataFrame):\n",
    "    dataFrame.drop([\"molecule_name\"], axis = 1)\n",
    "    a = pd.get_dummies(dataFrame.type)\n",
    "    dataFrame = pd.concat([dataFrame, a], axis = 'columns')\n",
    "    dataFrame = dataFrame.drop(\"type\", axis = 1)\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = prepData(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_final.drop([\"molecule_name\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = prepData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test_final.drop([\"molecule_name\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>EN_0</th>\n",
       "      <th>RD_0</th>\n",
       "      <th>hybri_0</th>\n",
       "      <th>pi_bonds_0</th>\n",
       "      <th>EN_1</th>\n",
       "      <th>RD_1</th>\n",
       "      <th>hybri_1</th>\n",
       "      <th>pi_bonds_1</th>\n",
       "      <th>Angle</th>\n",
       "      <th>1JHC</th>\n",
       "      <th>1JHN</th>\n",
       "      <th>2JHC</th>\n",
       "      <th>2JHH</th>\n",
       "      <th>2JHN</th>\n",
       "      <th>3JHC</th>\n",
       "      <th>3JHH</th>\n",
       "      <th>3JHN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.091953059611900</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70.528681978087036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.783119756038801</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.468408167182687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.783147496403011</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.471318021912978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.783156685329616</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.472066914238823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.091951618581363</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70.527651358140233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            distance  EN_0  RD_0  hybri_0  pi_bonds_0  EN_1  RD_1  hybri_1  \\\n",
       "0  1.091953059611900   2.2  0.43        0           0  2.55  0.82        3   \n",
       "1  1.783119756038801   2.2  0.43        0           0  2.20  0.43        0   \n",
       "2  1.783147496403011   2.2  0.43        0           0  2.20  0.43        0   \n",
       "3  1.783156685329616   2.2  0.43        0           0  2.20  0.43        0   \n",
       "4  1.091951618581363   2.2  0.43        0           0  2.55  0.82        3   \n",
       "\n",
       "   pi_bonds_1                Angle  1JHC  1JHN  2JHC  2JHH  2JHN  3JHC  3JHH  \\\n",
       "0           0   70.528681978087036     1     0     0     0     0     0     0   \n",
       "1           0  109.468408167182687     0     0     0     1     0     0     0   \n",
       "2           0  109.471318021912978     0     0     0     1     0     0     0   \n",
       "3           0  109.472066914238823     0     0     0     1     0     0     0   \n",
       "4           0   70.527651358140233     1     0     0     0     0     0     0   \n",
       "\n",
       "   3JHN  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size reduction for testing\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = round(0.10*X_final.shape[0])\n",
    "X_final = X_final[:size]\n",
    "X_test_final = X_test_final[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_regression(X, X_test, y, params, folds, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 50,\n",
    "          'min_child_samples': 79,\n",
    "          'min_data_in_leaf' : 100,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.2,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 1.0\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 3\n",
    "folds = KFold(n_splits=n_fold, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Mon Aug  5 11:57:49 2019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's l1: 1.91871\tvalid_1's l1: 2.14339\n",
      "[1000]\ttraining's l1: 1.90727\tvalid_1's l1: 2.13334\n",
      "[1500]\ttraining's l1: 1.90243\tvalid_1's l1: 2.12934\n",
      "[2000]\ttraining's l1: 1.89939\tvalid_1's l1: 2.12698\n",
      "Early stopping, best iteration is:\n",
      "[2111]\ttraining's l1: 1.89874\tvalid_1's l1: 2.12627\n",
      "Fold 2 started at Mon Aug  5 12:03:53 2019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's l1: 1.95946\tvalid_1's l1: 2.06974\n",
      "[1000]\ttraining's l1: 1.94736\tvalid_1's l1: 2.06313\n",
      "[1500]\ttraining's l1: 1.94184\tvalid_1's l1: 2.06016\n",
      "Early stopping, best iteration is:\n",
      "[1549]\ttraining's l1: 1.9414\tvalid_1's l1: 2.05987\n",
      "Fold 3 started at Mon Aug  5 12:08:23 2019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's l1: 2.05926\tvalid_1's l1: 1.90433\n",
      "[1000]\ttraining's l1: 2.04665\tvalid_1's l1: 1.89384\n",
      "[1500]\ttraining's l1: 2.04169\tvalid_1's l1: 1.89043\n",
      "Early stopping, best iteration is:\n",
      "[1822]\ttraining's l1: 2.03939\tvalid_1's l1: 1.88893\n",
      "CV mean score: 2.0250, std: 0.1000.\n"
     ]
    }
   ],
   "source": [
    "results = train_model_regression(X_final, X_test_final, y, params=params, folds = folds, model_type = 'lgb', eval_metric = 'mae', plot_feature_importance=False,\n",
    "                      verbose = 500, early_stopping_rounds=50, n_estimators = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.158174073891828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196.164427407916406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.789243447720843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.164427407916406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.158174073891828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.962237750641705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.141918845739218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-7.639949396582849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.401985430836731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.962237750641705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.141918845739218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-8.401985430836731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86.922627710065626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.208391713443220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.141918845739218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0    14.158174073891828\n",
       "1   196.164427407916406\n",
       "2     7.789243447720843\n",
       "3   196.164427407916406\n",
       "4    14.158174073891828\n",
       "5    91.962237750641705\n",
       "6     3.141918845739218\n",
       "7    -7.639949396582849\n",
       "8    -8.401985430836731\n",
       "9    91.962237750641705\n",
       "10    3.141918845739218\n",
       "11   -8.401985430836731\n",
       "12   86.922627710065626\n",
       "13    6.208391713443220\n",
       "14    3.141918845739218"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results['oof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.rename(columns={0:'scalar_coupling_constant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658154"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()\n",
    "result_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658154"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>dsgdb9nsd_000004</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     molecule_name  atom_index_0  atom_index_1  type\n",
       "0  4658147  dsgdb9nsd_000004             2             0  2JHC\n",
       "1  4658148  dsgdb9nsd_000004             2             1  1JHC\n",
       "2  4658149  dsgdb9nsd_000004             2             3  3JHH\n",
       "3  4658150  dsgdb9nsd_000004             3             0  1JHC\n",
       "4  4658151  dsgdb9nsd_000004             3             1  2JHC"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658147"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.drop(\"scalar_coupling_constant\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658154"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_submission.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658154"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_submission = pd.concat([sub, result_df], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4658147.,  4658148.,  4658149., ...,  7163687.,  7163688.,\n",
       "             nan])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_submission.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147.0</td>\n",
       "      <td>89.141558363661730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148.0</td>\n",
       "      <td>-10.558565834811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149.0</td>\n",
       "      <td>-10.558565834811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150.0</td>\n",
       "      <td>-10.558565834811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151.0</td>\n",
       "      <td>89.141558363661730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  scalar_coupling_constant\n",
       "0  4658147.0        89.141558363661730\n",
       "1  4658148.0       -10.558565834811615\n",
       "2  4658149.0       -10.558565834811615\n",
       "3  4658150.0       -10.558565834811615\n",
       "4  4658151.0        89.141558363661730"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_submission.to_csv(\"submission1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final DF creation\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4658147\n",
       "1    4658148\n",
       "2    4658149\n",
       "3    4658150\n",
       "4    4658151\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.rename(columns={0:'scalar_coupling_constant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.158174073891828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196.164427407916406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.789243447720843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.164427407916406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.158174073891828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scalar_coupling_constant\n",
       "0        14.158174073891828\n",
       "1       196.164427407916406\n",
       "2         7.789243447720843\n",
       "3       196.164427407916406\n",
       "4        14.158174073891828"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_DF = pd.concat([merge1, prediction], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505542"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_DF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_DF.to_csv(\"submission_Light1.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
